{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "659bc091",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-22T11:02:49.201064Z",
     "iopub.status.busy": "2024-10-22T11:02:49.200723Z",
     "iopub.status.idle": "2024-10-22T11:02:54.895217Z",
     "shell.execute_reply": "2024-10-22T11:02:54.894317Z"
    },
    "papermill": {
     "duration": 5.703575,
     "end_time": "2024-10-22T11:02:54.897555",
     "exception": false,
     "start_time": "2024-10-22T11:02:49.193980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from albumentations import HorizontalFlip, VerticalFlip, Rotate\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a54b9a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T11:02:54.909595Z",
     "iopub.status.busy": "2024-10-22T11:02:54.909142Z",
     "iopub.status.idle": "2024-10-22T11:02:54.921195Z",
     "shell.execute_reply": "2024-10-22T11:02:54.920400Z"
    },
    "papermill": {
     "duration": 0.020126,
     "end_time": "2024-10-22T11:02:54.923148",
     "exception": false,
     "start_time": "2024-10-22T11:02:54.903022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def augment_data(images, masks, save_path, augment=True):\n",
    "    size = (512, 512)  # Resize all images and masks to this size\n",
    "\n",
    "    for idx, (x, y) in tqdm(enumerate(zip(images, masks)), total=len(images)):\n",
    "        \"\"\" Extracting the name from the image path \"\"\"\n",
    "        name = x.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "        \"\"\" Reading image and mask \"\"\"\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)  # Read image\n",
    "        y = imageio.mimread(y)[0]  # Read mask\n",
    "\n",
    "        if augment:\n",
    "            # Apply augmentations: Horizontal Flip, Vertical Flip, and Rotate\n",
    "            aug = HorizontalFlip(p=1.0)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x1 = augmented[\"image\"]\n",
    "            y1 = augmented[\"mask\"]\n",
    "\n",
    "            aug = VerticalFlip(p=1.0)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x2 = augmented[\"image\"]\n",
    "            y2 = augmented[\"mask\"]\n",
    "\n",
    "            aug = Rotate(limit=45, p=1.0)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x3 = augmented[\"image\"]\n",
    "            y3 = augmented[\"mask\"]\n",
    "\n",
    "            # List of original and augmented images and masks\n",
    "            X = [x, x1, x2, x3]\n",
    "            Y = [y, y1, y2, y3]\n",
    "        else:\n",
    "            # No augmentation, just save the original image and mask\n",
    "            X = [x]\n",
    "            Y = [y]\n",
    "\n",
    "        # Save images and masks\n",
    "        index = 0\n",
    "        for i, m in zip(X, Y):\n",
    "            # Resize images and masks\n",
    "            i = cv2.resize(i, size)\n",
    "            m = cv2.resize(m, size)\n",
    "\n",
    "            # Create filenames for the augmented data\n",
    "            tmp_image_name = f\"{name}_{index}.png\"\n",
    "            tmp_mask_name = f\"{name}_{index}.png\"\n",
    "\n",
    "            # Create paths to save images and masks\n",
    "            image_path = os.path.join(save_path, \"image\", tmp_image_name)\n",
    "            mask_path = os.path.join(save_path, \"mask\", tmp_mask_name)\n",
    "\n",
    "            # Save images and masks to the directory\n",
    "            cv2.imwrite(image_path, i)\n",
    "            cv2.imwrite(mask_path, m)\n",
    "\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3386b37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T11:02:54.934394Z",
     "iopub.status.busy": "2024-10-22T11:02:54.934098Z",
     "iopub.status.idle": "2024-10-22T11:02:54.940737Z",
     "shell.execute_reply": "2024-10-22T11:02:54.940052Z"
    },
    "papermill": {
     "duration": 0.014294,
     "end_time": "2024-10-22T11:02:54.942572",
     "exception": false,
     "start_time": "2024-10-22T11:02:54.928278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding for reproducibility \"\"\"\n",
    "    np.random.seed(42)\n",
    "\n",
    "    \"\"\" Directories for images and masks \"\"\"\n",
    "    image_dir = \"/kaggle/input/multi-center-polypbd/PolypDB/PolypDB_modality_wise/WLI/images\"\n",
    "    mask_dir = \"/kaggle/input/multi-center-polypbd/PolypDB/PolypDB_modality_wise/WLI/masks\"\n",
    "    save_path_train = \"/kaggle/working/augmented_data/train\"\n",
    "    save_path_test = \"/kaggle/working/augmented_data/test\"\n",
    "\n",
    "    os.makedirs(os.path.join(save_path_train, \"image\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_path_train, \"mask\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_path_test, \"image\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_path_test, \"mask\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d45a2ba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T11:02:54.953960Z",
     "iopub.status.busy": "2024-10-22T11:02:54.953675Z",
     "iopub.status.idle": "2024-10-22T11:02:55.424207Z",
     "shell.execute_reply": "2024-10-22T11:02:55.423185Z"
    },
    "papermill": {
     "duration": 0.478644,
     "end_time": "2024-10-22T11:02:55.426543",
     "exception": false,
     "start_time": "2024-10-22T11:02:54.947899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_paths = sorted([os.path.join(image_dir, img) for img in os.listdir(image_dir) if img.endswith('.jpg') or img.endswith('.png')])\n",
    "mask_paths = sorted([os.path.join(mask_dir, mask) for mask in os.listdir(mask_dir) if mask.endswith('.jpg') or mask.endswith('.png')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4131ef8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T11:02:55.439076Z",
     "iopub.status.busy": "2024-10-22T11:02:55.438788Z",
     "iopub.status.idle": "2024-10-22T11:02:55.447297Z",
     "shell.execute_reply": "2024-10-22T11:02:55.446612Z"
    },
    "papermill": {
     "duration": 0.01624,
     "end_time": "2024-10-22T11:02:55.449203",
     "exception": false,
     "start_time": "2024-10-22T11:02:55.432963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(image_paths, mask_paths, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dadeff65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T11:02:55.460088Z",
     "iopub.status.busy": "2024-10-22T11:02:55.459817Z",
     "iopub.status.idle": "2024-10-22T11:09:26.651196Z",
     "shell.execute_reply": "2024-10-22T11:09:26.650220Z"
    },
    "papermill": {
     "duration": 391.199286,
     "end_time": "2024-10-22T11:09:26.653434",
     "exception": false,
     "start_time": "2024-10-22T11:02:55.454148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2870/2870 [05:54<00:00,  8.10it/s]\n",
      "100%|██████████| 718/718 [00:36<00:00, 19.47it/s]\n"
     ]
    }
   ],
   "source": [
    "augment_data(train_x, train_y, save_path_train, augment=True)\n",
    "augment_data(test_x, test_y, save_path_test, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f8c54b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T11:09:27.142783Z",
     "iopub.status.busy": "2024-10-22T11:09:27.142386Z",
     "iopub.status.idle": "2024-10-22T11:09:27.150571Z",
     "shell.execute_reply": "2024-10-22T11:09:27.149659Z"
    },
    "papermill": {
     "duration": 0.254265,
     "end_time": "2024-10-22T11:09:27.152453",
     "exception": false,
     "start_time": "2024-10-22T11:09:26.898188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PolypDB(Dataset):\n",
    "    def __init__(self, images_path, masks_path):\n",
    "        self.images_path = images_path\n",
    "        self.masks_path = masks_path\n",
    "        self.n_samples = len(images_path)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Reading image \"\"\"\n",
    "        image = cv2.imread(self.images_path[index], cv2.IMREAD_COLOR)\n",
    "        image = image / 255.0 \n",
    "        image = np.transpose(image, (2, 0, 1))\n",
    "        image = image.astype(np.float32)\n",
    "        image = torch.from_numpy(image)\n",
    "        \n",
    "        \"\"\" Reading masks \"\"\"\n",
    "        mask = cv2.imread(self.masks_path[index], cv2.IMREAD_GRAYSCALE)\n",
    "        mask = mask / 255.0 \n",
    "        mask = np.expand_dims(mask, axis=0)\n",
    "        mask = mask.astype(np.float32)\n",
    "        mask = torch.from_numpy(mask)\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "583aaa84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T11:09:27.650841Z",
     "iopub.status.busy": "2024-10-22T11:09:27.650083Z",
     "iopub.status.idle": "2024-10-22T11:09:27.668183Z",
     "shell.execute_reply": "2024-10-22T11:09:27.667293Z"
    },
    "papermill": {
     "duration": 0.272597,
     "end_time": "2024-10-22T11:09:27.670125",
     "exception": false,
     "start_time": "2024-10-22T11:09:27.397528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_c)\n",
    "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_c)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "class encoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = conv_block(in_c, out_c)\n",
    "        self.pool = nn.MaxPool2d((2, 2))\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        p = self.pool(x)\n",
    "        \n",
    "        return x, p\n",
    "    \n",
    "\n",
    "class decoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv = conv_block(out_c + out_c, out_c)\n",
    "        \n",
    "    def forward(self, inputs, skip):\n",
    "        x = self.up(inputs)\n",
    "        x = torch.cat([x, skip], axis=1)\n",
    "        x = self.conv(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "class build_unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        \"\"\" Encoder \"\"\"\n",
    "        self.e1 = encoder_block(3, 64)\n",
    "        self.e2 = encoder_block(64, 128)\n",
    "        self.e3 = encoder_block(128, 256)\n",
    "        self.e4 = encoder_block(256, 512)\n",
    "        \n",
    "        \"\"\" Bottleneck \"\"\"\n",
    "        self.b = conv_block(512, 1024)\n",
    "        \n",
    "        \"\"\" Decoder \"\"\"\n",
    "        self.d1 = decoder_block(1024, 512)\n",
    "        self.d2 = decoder_block(512, 256)\n",
    "        self.d3 = decoder_block(256, 128)\n",
    "        self.d4 = decoder_block(128, 64)\n",
    "        \n",
    "        \"\"\" Classifier \"\"\"\n",
    "        self.outputs = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Encoder \"\"\"\n",
    "        s1, p1 = self.e1(inputs)\n",
    "        s2, p2 = self.e2(p1)\n",
    "        s3, p3 = self.e3(p2)\n",
    "        s4, p4 = self.e4(p3)\n",
    "        \n",
    "        \"\"\" Bottleneck \"\"\"\n",
    "        b = self.b(p4)\n",
    "        \n",
    "        \"\"\" Decoder \"\"\"\n",
    "        d1 = self.d1(b, s4)\n",
    "        d2 = self.d2(d1, s3)\n",
    "        d3 = self.d3(d2, s2)\n",
    "        d4 = self.d4(d3, s1)\n",
    "        \n",
    "        outputs = self.outputs(d4)\n",
    "        \n",
    "        return outputs \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f557193",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T11:09:28.154498Z",
     "iopub.status.busy": "2024-10-22T11:09:28.154142Z",
     "iopub.status.idle": "2024-10-22T11:09:28.163487Z",
     "shell.execute_reply": "2024-10-22T11:09:28.162610Z"
    },
    "papermill": {
     "duration": 0.253878,
     "end_time": "2024-10-22T11:09:28.165621",
     "exception": false,
     "start_time": "2024-10-22T11:09:27.911743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        inputs = torch.sigmoid(inputs)  # Apply sigmoid activation\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2. * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n",
    "\n",
    "        return 1 - dice\n",
    "\n",
    "# Dice + Binary Cross-Entropy Loss\n",
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice_loss = 1 - (2. * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n",
    "        bce = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        dice_bce = bce + dice_loss\n",
    "\n",
    "        return dice_bce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f091dcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T11:09:28.656365Z",
     "iopub.status.busy": "2024-10-22T11:09:28.655958Z",
     "iopub.status.idle": "2024-10-22T11:09:28.749117Z",
     "shell.execute_reply": "2024-10-22T11:09:28.748312Z"
    },
    "papermill": {
     "duration": 0.339787,
     "end_time": "2024-10-22T11:09:28.751204",
     "exception": false,
     "start_time": "2024-10-22T11:09:28.411417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = PolypDB(\n",
    "        images_path=sorted([os.path.join(save_path_train, \"image\", img) for img in os.listdir(os.path.join(save_path_train, \"image\"))]),\n",
    "        masks_path=sorted([os.path.join(save_path_train, \"mask\", mask) for mask in os.listdir(os.path.join(save_path_train, \"mask\"))])\n",
    "    )\n",
    "test_dataset = PolypDB(\n",
    "        images_path=sorted([os.path.join(save_path_test, \"image\", img) for img in os.listdir(os.path.join(save_path_test, \"image\"))]),\n",
    "        masks_path=sorted([os.path.join(save_path_test, \"mask\", mask) for mask in os.listdir(os.path.join(save_path_test, \"mask\"))])\n",
    "    )\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cca05d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T11:09:29.279825Z",
     "iopub.status.busy": "2024-10-22T11:09:29.279443Z",
     "iopub.status.idle": "2024-10-22T11:09:29.344370Z",
     "shell.execute_reply": "2024-10-22T11:09:29.343426Z"
    },
    "papermill": {
     "duration": 0.315052,
     "end_time": "2024-10-22T11:09:29.346390",
     "exception": false,
     "start_time": "2024-10-22T11:09:29.031338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "019d53d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T11:09:29.836703Z",
     "iopub.status.busy": "2024-10-22T11:09:29.836294Z",
     "iopub.status.idle": "2024-10-22T11:09:31.668076Z",
     "shell.execute_reply": "2024-10-22T11:09:31.667255Z"
    },
    "papermill": {
     "duration": 2.079357,
     "end_time": "2024-10-22T11:09:31.670688",
     "exception": false,
     "start_time": "2024-10-22T11:09:29.591331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = build_unet().to(\"cuda\")  # Use GPU if available\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = DiceBCELoss()\n",
    "loss_fn = DiceBCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9039933",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T11:09:32.160977Z",
     "iopub.status.busy": "2024-10-22T11:09:32.160473Z",
     "iopub.status.idle": "2024-10-22T11:09:32.166295Z",
     "shell.execute_reply": "2024-10-22T11:09:32.165385Z"
    },
    "papermill": {
     "duration": 0.252832,
     "end_time": "2024-10-22T11:09:32.168391",
     "exception": false,
     "start_time": "2024-10-22T11:09:31.915559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def iou_score(preds, targets, smooth=1):\n",
    "    preds = (preds > 0.5).float()  # Apply a threshold to get binary predictions\n",
    "    targets = targets.float()\n",
    "    \n",
    "    intersection = (preds * targets).sum()\n",
    "    union = preds.sum() + targets.sum() - intersection\n",
    "    \n",
    "    return (intersection + smooth) / (union + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a137cc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T11:09:32.658594Z",
     "iopub.status.busy": "2024-10-22T11:09:32.658185Z",
     "iopub.status.idle": "2024-10-22T11:09:32.663182Z",
     "shell.execute_reply": "2024-10-22T11:09:32.662378Z"
    },
    "papermill": {
     "duration": 0.251621,
     "end_time": "2024-10-22T11:09:32.665209",
     "exception": false,
     "start_time": "2024-10-22T11:09:32.413588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time // 60)\n",
    "    elapsed_secs = int(elapsed_time % 60)\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fa15c7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T11:09:33.196261Z",
     "iopub.status.busy": "2024-10-22T11:09:33.195874Z",
     "iopub.status.idle": "2024-10-22T19:03:11.536239Z",
     "shell.execute_reply": "2024-10-22T19:03:11.535054Z"
    },
    "papermill": {
     "duration": 28418.626074,
     "end_time": "2024-10-22T19:03:11.538775",
     "exception": false,
     "start_time": "2024-10-22T11:09:32.912701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [23:06<00:00,  4.14it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:37<00:00, 19.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 23m 44s\n",
      "\tTrain Loss: 0.920\n",
      "\tVal. Loss: 0.939\n",
      "\tVal. IoU: 0.249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [23:08<00:00,  4.13it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:36<00:00, 19.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 23m 44s\n",
      "\tTrain Loss: 0.684\n",
      "\tVal. Loss: 0.657\n",
      "\tVal. IoU: 0.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [23:01<00:00,  4.15it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:36<00:00, 19.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 23m 38s\n",
      "\tTrain Loss: 0.502\n",
      "\tVal. Loss: 0.571\n",
      "\tVal. IoU: 0.535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [23:00<00:00,  4.16it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:36<00:00, 19.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 23m 36s\n",
      "\tTrain Loss: 0.416\n",
      "\tVal. Loss: 0.550\n",
      "\tVal. IoU: 0.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [23:04<00:00,  4.14it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:36<00:00, 19.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 23m 41s\n",
      "\tTrain Loss: 0.374\n",
      "\tVal. Loss: 0.486\n",
      "\tVal. IoU: 0.604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [23:03<00:00,  4.15it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:36<00:00, 19.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 23m 40s\n",
      "\tTrain Loss: 0.339\n",
      "\tVal. Loss: 0.444\n",
      "\tVal. IoU: 0.632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [23:03<00:00,  4.15it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:37<00:00, 19.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 23m 41s\n",
      "\tTrain Loss: 0.319\n",
      "\tVal. Loss: 0.452\n",
      "\tVal. IoU: 0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [23:04<00:00,  4.15it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:36<00:00, 19.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 23m 41s\n",
      "\tTrain Loss: 0.301\n",
      "\tVal. Loss: 0.496\n",
      "\tVal. IoU: 0.581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [23:03<00:00,  4.15it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:37<00:00, 19.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 23m 40s\n",
      "\tTrain Loss: 0.287\n",
      "\tVal. Loss: 0.482\n",
      "\tVal. IoU: 0.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [23:03<00:00,  4.15it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:36<00:00, 19.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 23m 40s\n",
      "\tTrain Loss: 0.270\n",
      "\tVal. Loss: 0.501\n",
      "\tVal. IoU: 0.604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [23:02<00:00,  4.15it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:37<00:00, 19.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Time: 23m 39s\n",
      "\tTrain Loss: 0.256\n",
      "\tVal. Loss: 0.386\n",
      "\tVal. IoU: 0.677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [23:04<00:00,  4.14it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:36<00:00, 19.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Time: 23m 41s\n",
      "\tTrain Loss: 0.247\n",
      "\tVal. Loss: 0.407\n",
      "\tVal. IoU: 0.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [23:04<00:00,  4.15it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:36<00:00, 19.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Time: 23m 41s\n",
      "\tTrain Loss: 0.237\n",
      "\tVal. Loss: 0.391\n",
      "\tVal. IoU: 0.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [23:03<00:00,  4.15it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:36<00:00, 19.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Time: 23m 40s\n",
      "\tTrain Loss: 0.226\n",
      "\tVal. Loss: 0.409\n",
      "\tVal. IoU: 0.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [23:02<00:00,  4.15it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:37<00:00, 19.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Time: 23m 40s\n",
      "\tTrain Loss: 0.217\n",
      "\tVal. Loss: 0.384\n",
      "\tVal. IoU: 0.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [23:04<00:00,  4.15it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:37<00:00, 19.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Time: 23m 41s\n",
      "\tTrain Loss: 0.208\n",
      "\tVal. Loss: 0.339\n",
      "\tVal. IoU: 0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [23:03<00:00,  4.15it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:37<00:00, 19.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Time: 23m 40s\n",
      "\tTrain Loss: 0.201\n",
      "\tVal. Loss: 0.380\n",
      "\tVal. IoU: 0.679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [23:02<00:00,  4.15it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:36<00:00, 19.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Time: 23m 39s\n",
      "\tTrain Loss: 0.192\n",
      "\tVal. Loss: 0.434\n",
      "\tVal. IoU: 0.639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [23:03<00:00,  4.15it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:36<00:00, 19.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Time: 23m 40s\n",
      "\tTrain Loss: 0.186\n",
      "\tVal. Loss: 0.362\n",
      "\tVal. IoU: 0.692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5740/5740 [23:05<00:00,  4.14it/s]\n",
      "Evaluating: 100%|██████████| 718/718 [00:36<00:00, 19.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Time: 23m 42s\n",
      "\tTrain Loss: 0.178\n",
      "\tVal. Loss: 0.358\n",
      "\tVal. IoU: 0.695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train(model, loader, optimizer, loss_fn, device):\n",
    "    epoch_loss = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    for x, y in tqdm(loader, desc='Training'):\n",
    "        x = x.to(device, dtype=torch.float32)\n",
    "        y = y.to(device, dtype=torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(loader)\n",
    "    return epoch_loss\n",
    "\n",
    "def evaluate(model, loader, loss_fn, device):\n",
    "    epoch_loss = 0.0\n",
    "    total_iou = 0.0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(loader, desc='Evaluating'):\n",
    "            x = x.to(device, dtype=torch.float32)\n",
    "            y = y.to(device, dtype=torch.float32)\n",
    "\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            total_iou += iou_score(y_pred, y)\n",
    "\n",
    "    epoch_loss /= len(loader)\n",
    "    average_iou = total_iou / len(loader)\n",
    "    return epoch_loss, average_iou\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 20  \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Training and validation\n",
    "    train_loss = train(model, train_loader, optimizer, loss_fn, device)\n",
    "    valid_loss, valid_iou = evaluate(model, test_loader, loss_fn, device)\n",
    "\n",
    "    # Logging the epoch results\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\tVal. Loss: {valid_loss:.3f}')\n",
    "    print(f'\\tVal. IoU: {valid_iou:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bebfc3",
   "metadata": {
    "papermill": {
     "duration": 10.205011,
     "end_time": "2024-10-22T19:03:31.818816",
     "exception": false,
     "start_time": "2024-10-22T19:03:21.613805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5798061,
     "sourceId": 9522499,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 28857.119676,
   "end_time": "2024-10-22T19:03:43.636888",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-22T11:02:46.517212",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
